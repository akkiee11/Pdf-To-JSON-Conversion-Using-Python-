{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................File Downloaded Succesfully..........................................................\n",
      "**************************************************Wait a Minute PDF is converted into CSV*******************************\n",
      "Congratulations...... Converted pdf to csv Succesfully........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Geocoded: A 1 400001 Gt Hospital Quarters,Fort: OK\n",
      "Geocoded: A 2 400001 M.R.A. Police Quarters,M.R.A. Road,Fort: OK\n",
      "Geocoded: A 3 400001 M.R.A. Bmc Colony,M.R.A. Road,Fort: OK\n",
      "Geocoded: A 4 400005 Sunder Nagari,Azad Nagari, Darya Nagar,Lala Nigam Road, Near Colaba Market,Sunder Nagar,Colaba: OK\n",
      "Geocoded: A 5 400005 Machchimar Nagar,Capt. Prakash Pethe Marg,Colaba: OK\n",
      "Geocoded: A 6 400005 Ganeshmurti Nagar Part No.1,2,3,Captain Prakash Pethe Marg,Ganeshmurthi Nagar,Colaba: OK\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "Inv = namedtuple('Inv', 'name')\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    \n",
    "    with requests.get(url) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "    return local_filename\n",
    "\n",
    "\n",
    "ap_url = 'http://stopcoronavirus.mcgm.gov.in/assets/docs/Containment-Zones.pdf'\n",
    "#Accessing Pdf File\n",
    "ap = download_file(ap_url)\n",
    "print(\"..................................................File Downloaded Succesfully..........................................................\")\n",
    "print(\"**************************************************Wait a Minute PDF is converted into CSV*******************************\")\n",
    "lines = []\n",
    "line_items=[]\n",
    "total_check = 0\n",
    "\n",
    "with pdfplumber.open(ap) as pdf:\n",
    "    pages = pdf.pages\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        patt=re.compile(r'[A-Z]* \\d[0-9]* \\d{6} (\\w)*')\n",
    "        for line in text.split('\\n'):\n",
    "                if patt.match(line):\n",
    "                    name=line\n",
    "                    line_items.append(Inv(name))\n",
    "                    df=pd.DataFrame(line_items)\n",
    "                    df.head()\n",
    "                    df.to_csv('stage11.csv') #Conversion Is Completed..\n",
    "                    \n",
    "print(\"Congratulations...... Converted pdf to csv Succesfully........\")                    \n",
    "                    \n",
    "                    \n",
    "                        \n",
    "#Module 2\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(\"root\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "API_KEY = \"AIzaSyB-boRA8KJLAJ7bvj-BRwCGqsl11YvTc3M\"\n",
    "# Backoff time sets how many minutes to wait between google pings when your API limit is hit\n",
    "BACKOFF_TIME = 30\n",
    "# Set your output file name here.\n",
    "output_filename = 'stage2.csv'\n",
    "# Set your input file here\n",
    "input_filename = \"stage11.csv\"\n",
    "# Specify the column name in your input data that contains addresses here\n",
    "address_column_name = \"name\"\n",
    "# Return Full Google Results? If True, full JSON results from Google are included in output\n",
    "RETURN_FULL_RESULTS = False\n",
    "\n",
    "#------------------ DATA LOADING --------------------------------\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "data = pd.read_csv(input_filename, encoding='utf8')\n",
    "\n",
    "if address_column_name not in data.columns:\n",
    "\traise ValueError(\"Missing Address column in input data\")\n",
    "\n",
    "# Form a list of addresses for geocoding:\n",
    "# Make a big list of all of the addresses to be processed.\n",
    "addresses = data[address_column_name].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#------------------\tFUNCTION DEFINITIONS ------------------------\n",
    "\n",
    "def get_google_results(address, api_key=None, return_full_response=False):\n",
    "   \n",
    "    # Set up your Geocoding url\n",
    "    geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?address={}\".format(address)\n",
    "    if api_key is not None:\n",
    "        geocode_url = geocode_url + \"&key={}\".format(api_key)\n",
    "        \n",
    "    # Ping google for the reuslts:\n",
    "    results = requests.get(geocode_url)\n",
    "    # Results will be in JSON format - convert to dict using requests functionality\n",
    "    results = results.json()\n",
    "    \n",
    "    # if there's no results or an error, return empty results.\n",
    "    if len(results['results']) == 0:\n",
    "        output = {\n",
    "            \"formatted_address\" : None,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"accuracy\": None,\n",
    "            \"google_place_id\": None,\n",
    "            \"type\": None,\n",
    "            \"postcode\": None\n",
    "        }\n",
    "    else:    \n",
    "        answer = results['results'][0]\n",
    "        output = {\n",
    "            \"formatted_address\" : answer.get('formatted_address'),\n",
    "            \"lat\": answer.get('geometry').get('location').get('lat'),\n",
    "            \"lng\": answer.get('geometry').get('location').get('lng'),\n",
    "            #\"accuracy\": answer.get('geometry').get('location_type'),\n",
    "           # \"google_place_id\": answer.get(\"place_id\"),\n",
    "            #\"type\": \",\".join(answer.get('types')),\n",
    "          #  \"postcode\": \",\".join([x['long_name'] for x in answer.get('address_components') \n",
    "                                 # if 'postal_code' in x.get('types')])\n",
    "        }\n",
    "        \n",
    "    # Append some other details:    \n",
    "    output['name'] = address\n",
    "   # output['number_of_results'] = len(results['results'])\n",
    "    output['status'] = results.get('status')\n",
    "    if return_full_response is True:\n",
    "        output['response'] = results\n",
    "    \n",
    "    return output\n",
    "\n",
    "#------------------ PROCESSING LOOP -----------------------------\n",
    "\n",
    "# Ensure, before we start, that the API key is ok/valid, and internet access is ok\n",
    "test_result = get_google_results(\"London, England\", API_KEY, RETURN_FULL_RESULTS)\n",
    "if (test_result['status'] != 'OK') or (test_result['formatted_address'] != 'London, UK'):\n",
    "    logger.warning(\"There was an error when testing the Google Geocoder.\")\n",
    "    raise ConnectionError('Problem with test results from Google Geocode - check your API key and internet connection.')\n",
    "\n",
    "# Create a list to hold results\n",
    "results = []\n",
    "# Go through each address in turn\n",
    "for address in addresses:\n",
    "    # While the address geocoding is not finished:\n",
    "    geocoded = False\n",
    "    while geocoded is not True:\n",
    "        # Geocode the address with google\n",
    "        try:\n",
    "            geocode_result = get_google_results(address, API_KEY, return_full_response=RETURN_FULL_RESULTS)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Major error with {}\".format(address))\n",
    "            logger.error(\"Skipping!\")\n",
    "            geocoded = True\n",
    "            \n",
    "        # If we're over the API limit, backoff for a while and try again later.\n",
    "        if geocode_result['status'] == 'OVER_QUERY_LIMIT':\n",
    "            logger.info(\"Hit Query Limit! Backing off for a bit.\")\n",
    "            time.sleep(BACKOFF_TIME * 60) # sleep for 30 minutes\n",
    "            geocoded = False\n",
    "        else:\n",
    "            # If we're ok with API use, save the results\n",
    "            # Note that the results might be empty / non-ok - log this\n",
    "            if geocode_result['status'] != 'OK':\n",
    "                logger.warning(\"Error geocoding {}: {}\".format(address, geocode_result['status']))\n",
    "            logger.debug(\"Geocoded: {}: {}\".format(address, geocode_result['status']))\n",
    "            results.append(geocode_result)           \n",
    "            geocoded = True\n",
    "\n",
    "    # Print status every 100 addresses\n",
    "    if len(results) % 100 == 0:\n",
    "    \tlogger.info(\"Completed {} of {} address\".format(len(results), len(addresses)))\n",
    "            \n",
    "    # Every 500 addresses, save progress to file(in case of a failure so you have something!)\n",
    "    if len(results) % 500 == 0:\n",
    "        pd.DataFrame(results).to_csv(\"{}_bak\".format(output_filename))\n",
    "\n",
    "# All done\n",
    "logger.info(\"Finished geocoding all addresses\")\n",
    "# Write the full results to csv using the pandas library.\n",
    "pd.DataFrame(results).to_csv(output_filename, encoding='utf8')\n",
    "\n",
    "\n",
    "print(\"*********************************Address Geocoded Succesfully*********************************\")\n",
    "\n",
    "import pandas\n",
    "data=pandas.read_csv('stage2.csv')\n",
    "data=data.drop(['formatted_address','status','latitude','longitude','accuracy','google_place_id','type','postcode'],axis=1)\n",
    "data.to_csv('summary.csv')\n",
    "\n",
    "\n",
    "\n",
    "import csv , json\n",
    "import os, sys, codecs\n",
    "\n",
    "arr = []\n",
    "jsonFilePath = \"markers.json\"\n",
    "with open ('summary.csv','r') as csvFile:\n",
    "    csvReader = csv.DictReader(csvFile)\n",
    "    #print(csvReader)\n",
    "    for csvRow in csvReader:\n",
    "        arr.append({'name':csvRow['name'],'lat':csvRow['lat'],'lng':csvRow['lng']})\n",
    "print(\"markers=\",arr)\n",
    "\n",
    "\n",
    "with open(jsonFilePath, \"w\") as jsonFile:\n",
    "    jsonFile.write(\"markers=\")\n",
    "    jsonFile.write(json.dumps(arr, indent=4))\n",
    "    jsonFile.write(json.dumps(arr, indent = 4))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"*********************************CSV TO JSON CONVERTED SUCCESFULLY*******************************************************\")    \n",
    "\n",
    "\n",
    "import ftplib\n",
    "filename=\"markers.json\"\n",
    "ftp=ftplib.FTP('ftp.actiondatasystems.com')\n",
    "ftp.login(\"akshay\",\"Sarla@2013\")\n",
    "ftp.pwd()\n",
    "myfile=open(\"markers.json\",'rb')\n",
    "ftp.storlines('STOR ' + filename, myfile)\n",
    "print(\"*******************************************File Uploded Succesfully*************************************\")\n",
    "ftp.dir()\n",
    "ftp.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
